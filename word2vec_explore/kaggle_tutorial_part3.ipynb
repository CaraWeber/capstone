{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16490, 300)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02941535, -0.0513059 , -0.08721951,  0.00082673,  0.08641035,\n",
       "        0.05378117,  0.12386004,  0.02094221, -0.00233172, -0.03997647,\n",
       "       -0.05452802, -0.11389782, -0.05407133,  0.07904044, -0.03324372,\n",
       "       -0.03749318, -0.00173147, -0.04767906, -0.08338775, -0.11164459,\n",
       "       -0.15238291,  0.00488032,  0.10066137,  0.08054902,  0.02391852,\n",
       "        0.05386177, -0.06786829, -0.04160012, -0.01197073, -0.04740219,\n",
       "        0.00924124,  0.05392271, -0.05645082,  0.03756255, -0.09991515,\n",
       "        0.02415238,  0.00039611, -0.02947001,  0.08141202, -0.00145684,\n",
       "       -0.05961829,  0.03514636,  0.06249267, -0.09909658, -0.00758574,\n",
       "       -0.02639271, -0.02670189, -0.02866178,  0.00241962,  0.13115166,\n",
       "       -0.05429085,  0.10124787,  0.0662581 , -0.04968387, -0.03145637,\n",
       "        0.0180555 ,  0.04574045, -0.06821576, -0.11828638, -0.0016918 ,\n",
       "       -0.07409013, -0.01686165,  0.01236163, -0.05372545,  0.04862688,\n",
       "        0.04574242, -0.05303368,  0.09391002,  0.08112244, -0.00422192,\n",
       "       -0.04005238,  0.02760607,  0.00892886, -0.02988199, -0.00681034,\n",
       "       -0.0415749 ,  0.0504805 , -0.02277474,  0.0142373 ,  0.13134943,\n",
       "        0.01308104,  0.05161436, -0.08067074, -0.14690886,  0.01406712,\n",
       "       -0.02153835, -0.04008792, -0.09640566, -0.02401035,  0.00054436,\n",
       "       -0.08182672, -0.00882797, -0.05469893,  0.05575334, -0.07665189,\n",
       "       -0.05846411,  0.01696249, -0.01715984, -0.04641825, -0.01637149,\n",
       "        0.00945554,  0.03295054,  0.05323526, -0.03300038, -0.03205688,\n",
       "        0.0252898 ,  0.01498545,  0.09603634, -0.0369519 , -0.11326384,\n",
       "        0.01521262, -0.01248066,  0.04426997,  0.06505869,  0.03326219,\n",
       "       -0.03387313,  0.14659536, -0.05468749,  0.01945699, -0.00053712,\n",
       "        0.03501061, -0.04889381, -0.03888711,  0.0144192 ,  0.04652375,\n",
       "        0.04881858, -0.01249881,  0.02477236,  0.01841935, -0.05512819,\n",
       "       -0.02602072,  0.03723134, -0.00166479, -0.00354069,  0.00721983,\n",
       "        0.04642992, -0.03785472, -0.04922114, -0.01038019,  0.02845418,\n",
       "       -0.03264262, -0.0317792 , -0.00360663,  0.06386092,  0.10663565,\n",
       "       -0.01379706, -0.0093578 ,  0.05797861, -0.12454054,  0.00165355,\n",
       "        0.05384172,  0.00716903,  0.04130162,  0.00625522,  0.01883406,\n",
       "        0.10119132, -0.09573235, -0.03889584,  0.10304942,  0.05444562,\n",
       "       -0.03154911,  0.06103844,  0.01561573, -0.08792891, -0.04490786,\n",
       "        0.00978079, -0.06707821,  0.079007  ,  0.08173575,  0.09592001,\n",
       "       -0.01226046, -0.07804027, -0.07388214, -0.00921888,  0.02116947,\n",
       "        0.02115728, -0.04902344, -0.02759024,  0.03871579, -0.04691457,\n",
       "        0.01645014, -0.04175691, -0.05259779, -0.05971882,  0.02217744,\n",
       "        0.01378323,  0.01075512, -0.07767966, -0.01231607, -0.0321694 ,\n",
       "        0.01073691, -0.05053141,  0.0945152 ,  0.03008901,  0.05003194,\n",
       "        0.03501929, -0.03346431,  0.06514564, -0.0552021 , -0.03395281,\n",
       "        0.05728696,  0.08462033,  0.01865851,  0.01183823,  0.07401844,\n",
       "       -0.04263904, -0.04795197, -0.03332783,  0.04777328,  0.08407339,\n",
       "       -0.00697077,  0.02000847, -0.04875921,  0.09139568,  0.06817057,\n",
       "        0.02165848,  0.10278323, -0.00942974,  0.12465142,  0.01317595,\n",
       "        0.04073924,  0.01318176,  0.04169437,  0.01864671,  0.00418268,\n",
       "       -0.05144982,  0.03966153, -0.07668474,  0.0562197 , -0.04269945,\n",
       "       -0.02201466, -0.02014882,  0.07187194, -0.09008151,  0.09726697,\n",
       "       -0.03226883, -0.04463998, -0.02477479,  0.02045206,  0.01317486,\n",
       "        0.02110091,  0.0753713 ,  0.03832731,  0.06141648, -0.01163056,\n",
       "        0.03776771,  0.0349764 ,  0.06634104,  0.04612731, -0.07273929,\n",
       "       -0.02088325, -0.08620748,  0.01883277,  0.05428178,  0.00510451,\n",
       "        0.05813451,  0.00820122, -0.04786093,  0.09754144,  0.01536953,\n",
       "        0.04294199,  0.00302934, -0.10429154,  0.04463128,  0.09787897,\n",
       "        0.0156408 ,  0.13277936,  0.02439562, -0.00671171,  0.05618805,\n",
       "       -0.02786546,  0.05840963,  0.01598293,  0.02943526,  0.01002778,\n",
       "       -0.06262884, -0.01200367, -0.08714407, -0.04274281,  0.08405463,\n",
       "       -0.04044201,  0.07681852,  0.10227553,  0.03396021, -0.08115121,\n",
       "        0.03937333, -0.09519311, -0.04139905, -0.01165256,  0.07128188,\n",
       "       -0.01200824,  0.08694517, -0.03519309, -0.05391744,  0.00527519,\n",
       "        0.00073632, -0.13003302,  0.00505472,  0.09159733,  0.19084345], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"flower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    counter = 0.\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        if counter%1000. == 0.:\n",
    "            print \"Review %d of %d\" % (counter, len(reviews))\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "creating average feature vecs for test reviews\n",
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return(words)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def review_to_sentences(review, tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3, encoding=\"utf8\")\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3, encoding=\"utf8\")\n",
    "unlabeled_train = pd.read_csv(\"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3, encoding=\"utf8\")\n",
    "\n",
    "num_features = 300\n",
    "\n",
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append(review_to_wordlist( review, remove_stopwords=True))\n",
    "    \n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features)\n",
    "\n",
    "print \"creating average feature vecs for test reviews\"\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, remove_stopwords=True))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n",
    "forest = forest.fit( trainDataVecs, train[\"sentiment\"] )\n",
    "result = forest.predict(testDataVecs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result})\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0]/5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  723.771988869 seconds\n"
     ]
    }
   ],
   "source": [
    "kmeans_clustering = KMeans(n_clusters = num_clusters)\n",
    "idx = kmeans_clustering.fit_predict(word_vectors)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_centroid_map = dict(zip(model.index2word, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "[u'crane']\n",
      "\n",
      "Cluster 1\n",
      "[u'veneer', u'crux', u'ambiguity', u'interpretation', u'metaphysical', u'therein']\n",
      "\n",
      "Cluster 2\n",
      "[u'sterile', u'lumbering', u'schlocky', u'disposable', u'ghastly', u'hideous', u'soulless', u'disturbingly', u'grotesque', u'relentless']\n",
      "\n",
      "Cluster 3\n",
      "[u'memorial', u'bc', u'exile', u'berlin', u'rome', u'paris', u'vienna']\n",
      "\n",
      "Cluster 4\n",
      "[u'agreement', u'armored', u'ambush', u'airline', u'auto', u'expedition', u'automobile', u'interrogation']\n",
      "\n",
      "Cluster 5\n",
      "[u'ants', u'locusts', u'raptors', u'wasps', u'rats']\n",
      "\n",
      "Cluster 6\n",
      "[u'ahmed', u'andr']\n",
      "\n",
      "Cluster 7\n",
      "[u'titular', u'mai', u'eponymous', u'aptly']\n",
      "\n",
      "Cluster 8\n",
      "[u'rude', u'polite']\n",
      "\n",
      "Cluster 9\n",
      "[u'abandons', u'proposes', u'arranges', u'arrange']\n"
     ]
    }
   ],
   "source": [
    "for cluster in xrange(0,10):\n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    \n",
    "    words = []\n",
    "    for i in xrange(0, len(word_centroid_map.values())):\n",
    "        if(word_centroid_map.values()[i] == cluster):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
